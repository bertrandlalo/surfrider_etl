{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bitsurfridercondaa4d29431e9f947419d6d850056118d13",
   "display_name": "Python 3.6.9 64-bit ('surfrider': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Surfrider ETL script"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import ContainerClient\n",
    "from azure.storage.blob import BlobClient\n",
    "\n",
    "''' blobContainer create a name_list of blobs within container'''\n",
    "''' params are container name (no full url) & storage conn string'''\n",
    "def blobInContainer(connection_s,container_n):\n",
    "    campaign_container = ContainerClient.from_connection_string(conn_str=connection_s, container_name=container_n)\n",
    "    blob_list = campaign_container.list_blobs()\n",
    "    blob_names_list = []\n",
    "    for blob in blob_list:\n",
    "        blob_names_list.append(blob.name)\n",
    "    return blob_names_list\n",
    "\n",
    "''' blobInfos provides basic information about a blob object'''\n",
    "''' params are blob_name only (no full url) & storage conn string'''\n",
    "def blobInfos(connection_s,container_n,blob_n):\n",
    "    blob_video = BlobClient.from_connection_string(conn_str=connection_s,container_name=container_n, blob_name=blob_n)\n",
    "    blob_video_url = blob_video.url\n",
    "    blob_video_prop = blob_video.get_blob_properties()\n",
    "    blob_video_prop_keys = blob_video_prop.keys()\n",
    "    print(\"blob name:\",blob_n)\n",
    "    print(\"blob URL:\",blob_video_url)\n",
    "    print(\"blob properties:\", blob_video_prop)\n",
    "    print(\"blob properties keys:\", blob_video_prop_keys)\n",
    "\n",
    "\n",
    "''' downloadBlob from Azure to local file system'''\n",
    "''' parameter is a blob client object from azure storage sdk'''\n",
    "def downloadBlob(blobclient):\n",
    "    with open(\"/tmp/\"+blobclient.blob_name, \"wb\") as my_blob_dl:\n",
    "        blob_data = blobclient.download_blob()\n",
    "        blob_data.readinto(my_blob_dl)\n",
    "    print(\"Blob %s downloaded\" %blobclient.blob_name)\n",
    "    print(\"Blob path: /tmp/%s\" %blobclient.blob_name)\n",
    "    path = \"/tmp/\"+blobclient.blob_name\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## AI Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import os\n",
    "import subprocess\n",
    "import requests\n",
    "\n",
    "def isAIready(url):\n",
    "    AI_ready = requests.get(url)\n",
    "    if AI_ready.status_code == 200:\n",
    "        print('AI is ready')\n",
    "        print('HTTP Status code: ',AI_ready.status_code)\n",
    "        print(AI_ready.headers)\n",
    "    else:\n",
    "        print(\"AI not found, an error has occured\")\n",
    "        print(\"Server Answer: \",AI_ready)\n",
    "        print(\"HTTP Status Code: \",AI_ready.status_code)\n",
    "        print(\"HTTP Status Code: \",AI_ready.raise_for_status())\n",
    "\n",
    "''' getPrediction function sends curl request to Surfrider AI'''\n",
    "''' video name is the name of a locally downloaded video from Azure'''\n",
    "''' video name is passed as an argument to curl_request script '''\n",
    "''' curl_request script sends actual POST request to Surfrider AI'''\n",
    "def getPrediction(video_name):\n",
    "    curl_request_script = ['./curl_request_param.sh',video_name]\n",
    "    output = []\n",
    "    request_answer = subprocess.Popen(curl_request_script, stdout=subprocess.PIPE)\n",
    "    i = 0\n",
    "    for line in request_answer.stdout:\n",
    "        print(line)\n",
    "        output.append(line)\n",
    "    return output\n",
    "\n",
    "\n",
    "''' jsonPrediction cast a prediction from getPrediction function '''\n",
    "''' from a list prediction to a string then dictionnary with json_loads '''\n",
    "def jsonPrediction(pred):\n",
    "    string_prediction = str(pred[0])[2:-3] #removing 2 x first and 3 last characters of pred\n",
    "    json_prediction = json.loads(string_prediction)\n",
    "    return json_prediction\n",
    "\n",
    "\n",
    "''' getTrashLabel return label from a frame_to_box'''\n",
    "def getTrashLabel(frame_2_box):\n",
    "    return frame_2_box['label']\n",
    "\n",
    "''' mapLabelTrashId is a switch that converts label to TrashId'''\n",
    "''' param is label that comes from AI predictions dictionnary jsonPrediction'''\n",
    "def mapLabel2TrashId(label):\n",
    "    switcher = { \n",
    "    \"Fishing or Hunting\":\"89B44BAA-69AA-4109-891A-128E012E7E07\",\n",
    "    \"Food Packaging\":\"185FEFA2-EEF2-47A8-873E-26032A4BB3C3\",\n",
    "    \"Unknown\":\"BB4DEA69-218A-40CC-A000-2AE17C37152C\",\n",
    "    \"Industrial or Construction Debris\":\"2A863E38-E5D0-455F-87CE-2B75DA29F59A\",\n",
    "    \"fragments\":\"ED401B92-DC24-44C0-A52A-34CE831092BF\",\n",
    "    \"Agricultural Waste\":\"36B2AFEB-7A7C-44B5-A790-5E5C73BA144D\",\n",
    "    \"others\":\"4BEC18FC-BC48-45B7-AFDA-6BA96BD80921\",\n",
    "    \"Common Household Items\":\"C68E90CF-6E65-4474-BC60-72E1C8513F55\",\n",
    "    \"plastic\":\"6961D0DB-928C-419E-9985-98EEEAF552C7\",\n",
    "    \"bottles\":\"9780940B-D06C-4AAB-8003-AB914981E87A\",\n",
    "    \"Drinking Bottles\":\"BCF549A8-AECD-4BC9-B9B8-B94A8F3758D5\",\n",
    "    \"Unknown10\":\"BC7BB564-BE04-4B4B-9913-FF69780B93A6\"\n",
    "    } \n",
    "    return switcher.get(label, \"nothing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse GPX file\n",
    "import gpxpy\n",
    "import gpxpy.gpx\n",
    "import json\n",
    "import subprocess\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from shapely.geometry import Point\n",
    "from functools import partial\n",
    "import pyproj\n",
    "from shapely.ops import transform\n",
    "from tqdm import tqdm\n",
    "\n",
    "def goproToGPX(video_name):\n",
    "    gopro2gpx_script = ['./gopro2gpx_param.sh',video_name]\n",
    "    result = subprocess.Popen(gopro2gpx_script, stdout=subprocess.PIPE)\n",
    "    output = []\n",
    "    i = 0\n",
    "    for line in result.stdout:\n",
    "        print(line)\n",
    "        output.append(line)\n",
    "    path='/tmp/'+video_name+'.gpx'\n",
    "    return path\n",
    "\n",
    "# Create GPX points list\n",
    "''' gpsPointList function extract gps points from gpx file '''\n",
    "''' gpxdata is a gpxpy object that returns data from a parsed gpx file'''\n",
    "''' gpsPointList return a list of dictionnary points with Time, Lat, Long, Elev'''\n",
    "def gpsPointList(gpxdata):\n",
    "    point_list = []\n",
    "    for track in gpxdata.tracks:\n",
    "        for segment in track.segments: \n",
    "            for point in segment.points:\n",
    "                point_info = {'Time':point.time,'Latitude':point.latitude,'Longitude':point.longitude,'Elevation':point.elevation}\n",
    "                point_list.append(point_info)\n",
    "    return point_list\n",
    "\n",
    "\n",
    "#===============================\n",
    "def getMediaInfo(mediafile):\n",
    "    cmd = \"mediainfo --Output=JSON %s\"%(mediafile)\n",
    "    proc = subprocess.Popen(cmd, shell=True,stderr=subprocess.PIPE, stdout=subprocess.PIPE)\n",
    "    stdout, stderr = proc.communicate()\n",
    "    data = json.loads(stdout)\n",
    "    return data\n",
    "\n",
    "#===============================\n",
    "def getDuration(mediafile):\n",
    "    data = getMediaInfo(mediafile)\n",
    "    duration = float(data['media']['track'][0]['Duration'])\n",
    "    return duration\n",
    "\n",
    "\n",
    "def createTime(time):\n",
    "    new_time = time\n",
    "    new_time = new_time + timedelta(seconds=1)\n",
    "    return new_time\n",
    "\n",
    "def createLatitude(lat1,lat2):\n",
    "    new_latitude = (lat1+lat2)/2\n",
    "    new_latitude = round(new_latitude,6)\n",
    "    return new_latitude\n",
    "\n",
    "def createLongitude(long1,long2):\n",
    "    new_longitude = (long1+long2)/2\n",
    "    new_latitude = round(new_longitude,6)\n",
    "    return new_longitude\n",
    "\n",
    "def createElevation(elev1,elev2):\n",
    "    new_elevation = (elev1+elev2)/2\n",
    "    new_elevation = round(new_elevation,6)\n",
    "    return new_elevation\n",
    "\n",
    "\n",
    "def fillGPS(inputGPSList,videoLength):\n",
    "    filledGps = inputGPSList.copy()\n",
    "    gps_length = len(filledGps)\n",
    "    iteration_length = int((filledGps[gps_length-1]['Time'] - filledGps[0]['Time']).total_seconds())\n",
    "    #print(iteration_length)\n",
    "    ## this section output a filled gps list of length iteration_length+1 = Delta T between last gps timestamp and first one\n",
    "    i = 0\n",
    "    while i < (iteration_length):\n",
    "#        print(i)\n",
    "        delta = filledGps[i+1]['Time']-filledGps[i]['Time']\n",
    "        delta = int(delta.total_seconds())\n",
    "        if delta > 1: # adding a newly created element at index i+1\n",
    "            #print(i)\n",
    "            missing_time = createTime(filledGps[i]['Time'])\n",
    "            missing_latitude = createLatitude(filledGps[i]['Latitude'],filledGps[i+1]['Latitude'])\n",
    "            missing_longitude = createLongitude(filledGps[i]['Longitude'],filledGps[i+1]['Longitude'])\n",
    "            missing_elevation = createElevation(filledGps[i]['Elevation'],filledGps[i+1]['Elevation'])\n",
    "            new_gps = {'Time':missing_time,'Latitude':missing_latitude,'Longitude':missing_longitude,'Elevation':missing_elevation}\n",
    "            filledGps.insert(i+1,new_gps)\n",
    "        i = i+1\n",
    "    ## this section add missing point at the end of the list, in case filledGps initial Delta time length is less than actual video length\n",
    "    if len(filledGps) < videoLength:\n",
    "        j = 0\n",
    "        while len(filledGps) < videoLength:\n",
    "            filledGps.insert(len(filledGps),filledGps[len(filledGps)-1])\n",
    "            j = j+1\n",
    "\n",
    "    return filledGps\n",
    "\n",
    "\n",
    "def longLat2shapePoint(gpsLongLatPoint):\n",
    "    gpsShapePoint = {'Time':gpsLongLatPoint['Time'],'the_geom':Point(gpsLongLatPoint['Longitude'],gpsLongLatPoint['Latitude']),'Elevation':gpsLongLatPoint['Elevation']}\n",
    "    return gpsShapePoint\n",
    "\n",
    "def longLat2shapeList(gpsLongLagList):\n",
    "    gpsShapeList = []\n",
    "    for gpsPoint in gpsLongLagList:\n",
    "        gpsShapePoint = longLat2shapePoint(gpsPoint)\n",
    "        gpsShapeList.append(gpsShapePoint)\n",
    "    return gpsShapeList\n",
    "\n",
    "\n",
    "\n",
    "def geometryTransfo(gpsShapePoint):\n",
    "    project = partial(\n",
    "    pyproj.transform,\n",
    "    pyproj.Proj(init='epsg:4326'), # source coordinate system\n",
    "    pyproj.Proj(init='epsg:2154')) # destination coordinate system\n",
    "\n",
    "    geo1 = gpsShapePoint['the_geom']\n",
    "    geo2 = transform(project,geo1)\n",
    "\n",
    "    return geo2\n",
    "\n",
    "def gps2154(gpsShapePointsFilled):\n",
    "    gps2154Points = []\n",
    "    for point in tqdm(gpsShapePointsFilled):\n",
    "        geo2154 = geometryTransfo(point)\n",
    "        gps2154Point = {'Time':point['Time'],'the_geom':geo2154,'Elevation':point['Elevation']}\n",
    "        gps2154Points.append(gps2154Point)\n",
    "    return gps2154Points"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PostGre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "def pgOpenConnection(conn_string):\n",
    "    try:\n",
    "        conn = psycopg2.connect(conn_string)\n",
    "        print(\"Connection established\")\n",
    "        return conn\n",
    "    except psycopg2.OperationalError as err:\n",
    "        print(\"Connection could not established: \",err)\n",
    "    #return conn\n",
    "\n",
    "# Function to close connection to PG server\n",
    "def pgCloseConnection(connection):\n",
    "    try:\n",
    "        connection.close()\n",
    "        print(\"PG connection closed\")\n",
    "    except:\n",
    "        print(\"PG connection could not close successfully\")\n",
    "\n",
    "# Label to TrashId PGSQL Data Model\n",
    "def mapLabel2TrashIdPG(label):\n",
    "    switcher = { \n",
    "        \"others\":\"1\", #\"autre dechet\" in PG Data Model mapped to IA \"others\" label\n",
    "        \"dechet agricole\":\"2\",\n",
    "        \"bottles\":\"3\", #\"bouteille boisson\" in PG Data Model mapped to IA \"bottles\" label\n",
    "        \"fragments\":\"4\",#\"industriel ou construction in PG Data Model mapped to IA \"fragments\" label\n",
    "        \"peche et chasse\":\"5\",\n",
    "        \"emballage alimentaire\":\"6\",\n",
    "        \"objet vie courante\":\"7\",\n",
    "        \"autres dechets +10\":\"8\"\n",
    "    } \n",
    "    return switcher.get(label, \"nothing\")\n",
    "\n",
    "# Dummy Function to give GPS point to Detected Trash, based on TrashId\n",
    "def trashGPS(trashId,gps2154Points):\n",
    "    length = len(gps2154Points)+1\n",
    "    gpsIndex = trashId % length\n",
    "    return gpsIndex\n",
    "\n",
    "\n",
    "# INSERT REQUEST: point parameter + trashTypeId + Timestamp\n",
    "def trashInsert(gps2154Point,trashTypeId,cursor,connexion):\n",
    "    point = 'POINT(' + str(gps2154Point['the_geom'].coords.xy[0][0]) + ' ' + str(gps2154Point['the_geom'].coords.xy[1][0]) + ')'\n",
    "    elevation = gps2154Point['Elevation']\n",
    "    timestamp = gps2154Point['Time']\n",
    "    cursor.execute(\"INSERT INTO public.trash (id, id_ref_campaign_fk,the_geom, elevation, id_ref_trash_type_fk,brand_type,time ) VALUES (DEFAULT, '003d8675-29e3-4cde-a315-095ac2ec80bc',%s,%s,%s,%s,%s) RETURNING id;\", (point,elevation,trashTypeId,'icetea',timestamp))\n",
    "    connexion.commit()\n",
    "    row_id = cursor.fetchone()[0]\n",
    "    return row_id"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def main():\n",
    "\n",
    "    ######## Pipeline Step0: Get Video to predict and insert#########\n",
    "    print('######## Pipeline Step0: Get Video from Azure Blob Storage #########')\n",
    "    # blob storage connection string\n",
    "    connection_string = os.getenv(\"CONN_STRING\")\n",
    "\n",
    "    # get list of blobs in container campaign0\n",
    "    campaign_container_name = 'campaign0'\n",
    "    blobs_campaign0 = blobInContainer(connection_string,campaign_container_name)\n",
    "    print(blobs_campaign0)\n",
    "\n",
    "    # get infos of blob 'goproshort-480p.mov' \n",
    "    blob_video_name = 'goproshort-480p.mov'   \n",
    "    blobInfos(connection_string,campaign_container_name,blob_video_name)\n",
    "\n",
    "    # download locally in /tmp blob video\n",
    "    blob_video0 = BlobClient.from_connection_string(conn_str=connection_string,container_name=campaign_container_name, blob_name=blob_video_name)\n",
    "    downloadBlob(blob_video0)\n",
    "\n",
    "    ######## Pipeline Step 1bis: AI Trash prediction #########\n",
    "    print('######## Pipeline Step 1bis: AI Trash prediction #########')\n",
    "    isAIready('http://aiapisurfrider.northeurope.cloudapp.azure.com:5000')\n",
    "    # get predictions from AI on goproshort-480p.mov\n",
    "    prediction = getPrediction(blob_video_name)\n",
    "\n",
    "    # cast prediction to JSON/Dictionnary format\n",
    "    json_prediction = jsonPrediction(prediction)\n",
    "    json_prediction\n",
    "\n",
    "    ######## Pipeline Step 1: GPX creation ########\n",
    "    print('######## Pipeline Step 1: GPX creation ########')\n",
    "    video_name = '28022020_Boudigau_4.MP4'\n",
    "    gpx_path = goproToGPX(video_name)\n",
    "    gpx_path\n",
    "\n",
    "    # GPX parsing\n",
    "    gpx_file = open(gpx_path,'r',encoding='utf-8')\n",
    "    gpx_data = gpxpy.parse(gpx_file) # data from parsed gpx file\n",
    "\n",
    "    # GPS Points\n",
    "    gpsPoints = gpsPointList(gpx_data)\n",
    "\n",
    "    # Video duration\n",
    "    print(\"\\n\")\n",
    "    video_duration = getDuration('/tmp/'+video_name)\n",
    "    print(\"Video duration in second from metadata:\",video_duration)\n",
    "\n",
    "    # GPS file duration\n",
    "    timestampDelta = gpsPoints[len(gpsPoints)-1]['Time'] - gpsPoints[0]['Time']\n",
    "    print(\"GPS file time coverage in second: \",timestampDelta.seconds)\n",
    "\n",
    "    ######## Pipeline Step 2: Create gpsPointFilled ########\n",
    "    print('######## Pipeline Step 2: Create gpsPointFilled ########')\n",
    "    video_duration_sup = int(video_duration)+1\n",
    "    gpsPointsFilled = fillGPS(gpsPoints,video_duration_sup)\n",
    "\n",
    "    ######## Pipeline Step 3: GPS shapePoints ########\n",
    "    print('######## Pipeline Step 3: GPS shapePoints ########')\n",
    "    gpsShapePointsFilled = longLat2shapeList(gpsPointsFilled)\n",
    "\n",
    "    ######## Pipeline Step 4: 2154 geometry conversion ########\n",
    "    print('######## Pipeline Step 4: 2154 Geometry conversion ########')\n",
    "    gps2154PointsFilled = gps2154(gpsShapePointsFilled)\n",
    "\n",
    "    ######## Pipeline Step 5: PostGre INSERT ########\n",
    "    print('######## Pipeline Step 5: PostGre INSERT ########')\n",
    "    # Postgre connection pre-requesite\n",
    "    # Update connection string information from env variables\n",
    "    pgserver = os.getenv(\"PGSERVER\")\n",
    "    pgdatabase = os.getenv(\"PGDATABASE\")\n",
    "    pgusername = os.getenv(\"PGUSERNAME\")\n",
    "    pgpassword = os.getenv(\"PGPWD\")\n",
    "    sslmode = \"require\"\n",
    "\n",
    "    # Open pgConnection, create cursor\n",
    "    conn_string = \"host={0} user={1} dbname={2} password={3} sslmode={4}\".format(pgserver, pgusername, pgdatabase, pgpassword, sslmode)\n",
    "    pgconnection = pgOpenConnection(conn_string)\n",
    "    cursor = pgconnection.cursor()\n",
    "\n",
    "\n",
    "    # INSERTING all detected_trash within PostGre\n",
    "    rowID_list = []\n",
    "    for prediction in tqdm(json_prediction['detected_trash']):\n",
    "        try: \n",
    "            # get GPS coordinate\n",
    "            trashTypeId= prediction['id']\n",
    "            gpsIndexId = trashGPS(trashTypeId,gps2154PointsFilled)\n",
    "            gpsTrashTypeId = gps2154PointsFilled[gpsIndexId]\n",
    "            # get TrashTypeId from AI prediction\n",
    "            label = getTrashLabel(prediction)\n",
    "            trashType = mapLabel2TrashIdPG(label)\n",
    "            # INSERT within PostGRE\n",
    "            rowID = trashInsert(gpsTrashTypeId,trashType,cursor,pgconnection)\n",
    "            print(\"prediction:\",prediction['id'])\n",
    "            print(\"rowID:\",rowID)\n",
    "            rowID_list.append(rowID)\n",
    "        except:\n",
    "            print(\"There was an issue inserting Trash id:\" + str(prediction['id']) + \" within PostGre\")\n",
    "    print(\"Successfully inserted \" + str(len(rowID_list)) + \" Trashes within Trash table\")    \n",
    "\n",
    "    # Close PG connection\n",
    "    pgCloseConnection(pgconnection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute main function\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ]
}