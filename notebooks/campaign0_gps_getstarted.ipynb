{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bitcondacadf76f2c1054d4581372baf88a91024",
   "display_name": "Python 3.6.9 64-bit (conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gps_path = '../gpssamples'\n",
    "gpx_file = '3145554.gpx'\n",
    "kml_file = '19022020_Adour_6.kml'\n",
    "gpx_path = os.path.join(gps_path,gpx_file)\n",
    "kml_path = os.path.join(gps_path,kml_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GPX file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pypi.org/project/gpxpy/\n",
    "import gpxpy\n",
    "import gpxpy.gpx \n",
    "gpx_file = open(gpx_path,'r',encoding='utf-8')\n",
    "gpx = gpxpy.parse(gpx_file) # data from parsed gpx file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' gpsPointList function extract gps points from gpx file '''\n",
    "''' gpxdata is a gpxpy object that returns data from a parsed gpx file'''\n",
    "''' gpsPointList return a list of dictionnary points with Time, Lat, Long, Elev'''\n",
    "def gpsPointList(gpxdata):\n",
    "    point_list = []\n",
    "    for track in gpxdata.tracks:\n",
    "        for segment in track.segments: \n",
    "            for point in segment.points:\n",
    "                point_info = {'Time':point.time,'Latitude':point.latitude,'Longitude':point.longitude,'Elevation':point.elevation}\n",
    "                point_list.append(point_info)\n",
    "    return point_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypoints = gpsPointList(gpx)\n",
    "for i in range(0,10):\n",
    "    print(mypoints[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0,10):\n",
    "    print(mypoints[i]['Time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## KML File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pykml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://developers.google.com/kml/documentation/kml_tut#placemarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykml import parser\n",
    "root = parser.fromstring(open(kml_path, 'r').read())\n",
    "print (root.Document.Placemark.Point.coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting Placemark child info example\n",
    "for placemark in root.Document.Placemark:\n",
    "    print(placemark.name)\n",
    "    print(placemark.styleUrl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placemark 0 example: getting Extended info\n",
    "for placemark in root.Document.Placemark:\n",
    "    if(placemark.name == 0):\n",
    "        print(placemark.name)\n",
    "        test = placemark\n",
    "\n",
    "for SimpleData in test.ExtendedData.SchemaData.SimpleData:\n",
    "        print(SimpleData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' placeMarkNameList function takes a parsed kml file input'''\n",
    "''' then returns the a list of Placemark names'''\n",
    "def placemarkNameList(kmlroot):\n",
    "    placemark_name = []\n",
    "    for placemark in kmlroot.Document.Placemark:\n",
    "        placemark_name.append(placemark.name)\n",
    "    return placemark_name\n",
    "\n",
    "# Testing placemarkNameList function\n",
    "mykmlPlacemarkList = placemarkNameList(root)\n",
    "print(mykmlPlacemarkList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' getPlacemarkExtendedData function takes a placemarkname list input '''\n",
    "''' then return'''\n",
    "def getPlacemarkExtendedData(placemarkname):\n",
    "    placemarkExtendedData_list = []\n",
    "    for i in range(1,len(mykmlPlacemarkList)-1):\n",
    "        \n",
    "        placemarkExtendedData_info = []\n",
    "        for placemark in root.Document.Placemark:\n",
    "            if(placemark.name == mykmlPlacemarkList[i]):\n",
    "                #print(placemark.name)\n",
    "                temp = placemark\n",
    "        for SimpleData in temp.ExtendedData.SchemaData.SimpleData:\n",
    "                #print(SimpleData)\n",
    "                placemarkExtendedData_info.append(SimpleData)\n",
    "\n",
    "        placemarkExtendedData_list.append(placemarkExtendedData_info)\n",
    "    return placemarkExtendedData_list\n",
    "\n",
    "# testing getPlacemarkExtendedData function\n",
    "mykmlPlacemarkExtendedDataList = getPlacemarkExtendedData(mykmlPlacemarkList)\n",
    "print(mykmlPlacemarkExtendedDataList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' placemarkgpsDico function takes extendeddata input '''\n",
    "''' then returns a gps dico from it'''\n",
    "def placemarkGpsDico(extendeddata):\n",
    "    dico = {\"Time\":str(extendeddata[7])+\" \"+str(extendeddata[8]),\"Latitude\":extendeddata[1],\"Longitude\":extendeddata[2],\"Elevation\":extendeddata[6]}\n",
    "    return dico\n",
    "\n",
    "# testing placemarkGpsDico\n",
    "myextendeddatadico = placemarkGpsDico(mykmlPlacemarkExtendedDataList[0])\n",
    "print(myextendeddatadico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpsPlacemarkList(placemarkExtendedDataList):\n",
    "    gpsPlacemark_List = []\n",
    "    for i in range(0,len(placemarkExtendedDataList)):\n",
    "        gpsPlacemark_List.append(placemarkGpsDico(placemarkExtendedDataList[i]))\n",
    "    return gpsPlacemark_List\n",
    "\n",
    "myGpsPlacemarkList =  gpsPlacemarkList(mykmlPlacemarkExtendedDataList)\n",
    "myGpsPlacemarkList"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### azure pre-requesite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get connection_string\n",
    "import os\n",
    "connection_string = os.getenv(\"CONN_STRING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import container client and enumerate blob within container\n",
    "from azure.storage.blob import ContainerClient\n",
    "\n",
    "def blobInContainer(connection_s,container_n):\n",
    "    campaign_container = ContainerClient.from_connection_string(conn_str=connection_s, container_name=container_n)\n",
    "    blob_list = campaign_container.list_blobs()\n",
    "    blob_names_list = []\n",
    "    for blob in blob_list:\n",
    "        blob_names_list.append(blob.name)\n",
    "    return blob_names_list\n",
    "\n",
    "blobs_campaign0 = blobInContainer(connection_string,'campaign0')\n",
    "print(blobs_campaign0)\n",
    "\n",
    "# Get Blob Video info\n",
    "from azure.storage.blob import BlobClient\n",
    "\n",
    "def blobInfos(connection_s,container_n,blob_n):\n",
    "    blob_video = BlobClient.from_connection_string(conn_str=connection_s,container_name=container_n, blob_name=blob_n)\n",
    "    blob_video_url = blob_video.url\n",
    "    blob_video_prop = blob_video.get_blob_properties()\n",
    "    blob_video_prop_keys = blob_video_prop.keys()\n",
    "    print(\"blob name:\",blob_n)\n",
    "    print(\"blob URL:\",blob_video_url)\n",
    "    print(\"blob properties:\", blob_video_prop)\n",
    "    print(\"blob properties keys:\", blob_video_prop_keys)\n",
    "\n",
    "blob_video_name = 'vid1-4K4.mp4'\n",
    "blobInfos(connection_string,'campaign0',blob_video_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobClient\n",
    "blob_video0 = BlobClient.from_connection_string(conn_str=connection_string,container_name=\"campaign0\", blob_name=\"vid1-4K4.mp4\")\n",
    "\n",
    "''' function to download blob from Azure to local file system'''\n",
    "''' parameter is a blob client object from azure storage sdk'''\n",
    "def downloadBlob(blobclient):\n",
    "    with open(\"/tmp/\"+blobclient.blob_name, \"wb\") as my_blob_dl:\n",
    "        blob_data = blobclient.download_blob()\n",
    "        blob_data.readinto(my_blob_dl)\n",
    "    print(\"Blob %s downloaded\" %blobclient.blob_name)\n",
    "    print(\"Blob path: /tmp/%s\" %blobclient.blob_name)\n",
    "\n",
    "downloadBlob(blob_video0)\n",
    "# this function should handle connection issue"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### REST requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/3777301/how-to-call-a-shell-script-from-python-code\n",
    "#https://stackoverflow.com/questions/325463/launch-a-shell-command-with-in-a-python-script-wait-for-the-termination-and-ret\n",
    "\n",
    "import subprocess\n",
    "\n",
    "''' getPrediction function sends curl request to Surfrider AI'''\n",
    "''' video name is the name of a locally downloaded video from Azure'''\n",
    "''' video name is passed as an argument to curl_request script '''\n",
    "''' curl_request script sends actual POST request to Surfrider AI'''\n",
    "def getPrediction(video_name):\n",
    "    curl_request_script = ['./curl_request_param.sh',video_name]\n",
    "    output = []\n",
    "    request_answer = subprocess.Popen(curl_request_script, stdout=subprocess.PIPE)\n",
    "    for line in request_answer.stdout:\n",
    "        print(line)\n",
    "        output.append(line)\n",
    "    return output\n",
    "\n",
    "# this function should handle connection issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions from AI on vid1-4K4.MP4\n",
    "prediction = getPrediction('vid1-4K4.mp4')\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### JSON Decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "''' jsonPrediction cast a prediction from getPrediction function '''\n",
    "''' and cast the list prediction as a string then dictionnary with json_loads '''\n",
    "def jsonPrediction(pred):\n",
    "    string_prediction = str(pred[0])[2:-3] #removing 2 x first and 3 last characters of pred\n",
    "    json_prediction = json.loads(string_prediction)\n",
    "    return json_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_prediction = jsonPrediction(prediction)\n",
    "json_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame_to_box in json_prediction['detected_trash']:\n",
    "    print(frame_to_box)\n",
    "    print(frame_to_box['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' getTrashLabel return label from a frame_to_box'''\n",
    "def getTrashLabel(frame_2_box):\n",
    "    return frame_to_box['label']\n",
    "\n",
    "test_f2b = {'frame_to_box': {'2': [0.45, 0.44, 0.5, 0.5]}, 'id': 0, 'label': 'fragments'}\n",
    "getTrashLabel(test_f2b['frame_to_box'])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### requests - skip for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make first GET Request using requests module\n",
    "import requests\n",
    "r_get = requests.get('https://github.com/timeline.json')\n",
    "print(r_get.text)\n",
    "# Make first POST Request using requests module\n",
    "r_post = requests.post(\"http://httpbin.org/post\")\n",
    "print(r_post.text) # response in text format\n",
    "print(r_post.json()) # response is json formated\n",
    "\n",
    "# Video POST request example\n",
    "desktop = '/Users/clement/Desktop/'\n",
    "video = 'vid1-4K.MP4'\n",
    "video_path = os.path.join(desktop,video)\n",
    "url = 'http://aiapisurfrider.northeurope.cloudapp.azure.com:5000'\n",
    "myfile = {'file': open(video_path ,'rb')}\n",
    "#myairequest = requests.post(url, files = myfile)\n",
    "\n",
    "# Image POST request example\n",
    "desktop = '/Users/clement/Desktop/'\n",
    "img = 'G0061735.JPG'\n",
    "img_path = os.path.join(desktop,img)\n",
    "url = 'http://aiapisurfrider.northeurope.cloudapp.azure.com:5000'\n",
    "myfile = {'file': open(img_path ,'rb')}\n",
    "myairequest = requests.post(url, files = myfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SQL Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sql odbc driver and connect to SQL DB\n",
    "import os\n",
    "import pyodbc\n",
    "server = os.getenv(\"SERVER\")\n",
    "database = os.getenv(\"DATABASE\")\n",
    "username = os.getenv(\"USERNAME\")\n",
    "password = os.getenv(\"PWD\")\n",
    "driver= '{ODBC Driver 17 for SQL Server}'\n",
    "cnxn = pyodbc.connect('DRIVER='+driver+';SERVER='+server+';PORT=1433;DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "cursor = cnxn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Query on dbo.Trash_Type\n",
    "cursor.execute(\"SELECT * FROM dbo.Trash_Type\")\n",
    "row = cursor.fetchone()\n",
    "while row:\n",
    "    print (str(row[0]))\n",
    "    print (str(row[1]))\n",
    "    row = cursor.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapLabel2TrashId(label):\n",
    "    switcher = { \n",
    "    \"Fishing or Hunting\":\"89B44BAA-69AA-4109-891A-128E012E7E07\",\n",
    "    \"Food Packaging\":\"185FEFA2-EEF2-47A8-873E-26032A4BB3C3\",\n",
    "    \"Unknown\":\"BB4DEA69-218A-40CC-A000-2AE17C37152C\",\n",
    "    \"Industrial or Construction Debris\":\"2A863E38-E5D0-455F-87CE-2B75DA29F59A\",\n",
    "    \"fragments\":\"ED401B92-DC24-44C0-A52A-34CE831092BF\",\n",
    "    \"Agricultural Waste\":\"36B2AFEB-7A7C-44B5-A790-5E5C73BA144D\",\n",
    "    \"others\":\"4BEC18FC-BC48-45B7-AFDA-6BA96BD80921\",\n",
    "    \"Common Household Items\":\"C68E90CF-6E65-4474-BC60-72E1C8513F55\",\n",
    "    \"plastic\":\"6961D0DB-928C-419E-9985-98EEEAF552C7\",\n",
    "    \"bottles\":\"9780940B-D06C-4AAB-8003-AB914981E87A\",\n",
    "    \"Drinking Bottles\":\"BCF549A8-AECD-4BC9-B9B8-B94A8F3758D5\",\n",
    "    \"Unknown10\":\"BC7BB564-BE04-4B4B-9913-FF69780B93A6\"\n",
    "    } \n",
    "    return switcher.get(label, \"nothing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Trash INSERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' trashInsert execute INSERT request to dbo.Trash table'''\n",
    "''' parameter to indsert is a trashTypeId defined in Trash_Type table'''\n",
    "def trashInsert(trashTypeId,cursor,cnxn):\n",
    "    cursor.execute(\"INSERT dbo.Trash (Id,CampaignId,Latitude,Longitude,TrashTypeId,Precision,AI_Version) VALUES (NEWID(),'8D21A132-CF4B-404E-B287-C40A2F12D305','50.797731', '2.179029', ? ,'0.95','0')\",trashTypeId)\n",
    "    cnxn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executing INSERT for all trash detected in json_prediction from vid1-4K4.MP4\n",
    "for frame_to_box in json_prediction['detected_trash']:\n",
    "    print(frame_to_box)\n",
    "    trashLabel = getTrashLabel(frame_to_box)\n",
    "    print(trashLabel)\n",
    "    mapLabel = mapLabel2TrashId(trashLabel)\n",
    "    print(mapLabel)\n",
    "    trashInsert(mapLabel,cursor,cnxn)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trash End to End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import ContainerClient\n",
    "from azure.storage.blob import BlobClient\n",
    "import json \n",
    "import os\n",
    "import pyodbc\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' blobContainer create a name_list of blobs within container'''\n",
    "''' params are container name (no full url) & storage conn string'''\n",
    "def blobInContainer(connection_s,container_n):\n",
    "    campaign_container = ContainerClient.from_connection_string(conn_str=connection_s, container_name=container_n)\n",
    "    blob_list = campaign_container.list_blobs()\n",
    "    blob_names_list = []\n",
    "    for blob in blob_list:\n",
    "        blob_names_list.append(blob.name)\n",
    "    return blob_names_list\n",
    "\n",
    "''' blobInfos provides basic information about a blob object'''\n",
    "''' params are blob_name only (no full url) & storage conn string'''\n",
    "def blobInfos(connection_s,container_n,blob_n):\n",
    "    blob_video = BlobClient.from_connection_string(conn_str=connection_s,container_name=container_n, blob_name=blob_n)\n",
    "    blob_video_url = blob_video.url\n",
    "    blob_video_prop = blob_video.get_blob_properties()\n",
    "    blob_video_prop_keys = blob_video_prop.keys()\n",
    "    print(\"blob name:\",blob_n)\n",
    "    print(\"blob URL:\",blob_video_url)\n",
    "    print(\"blob properties:\", blob_video_prop)\n",
    "    print(\"blob properties keys:\", blob_video_prop_keys)\n",
    "\n",
    "\n",
    "''' downloadBlob from Azure to local file system'''\n",
    "''' parameter is a blob client object from azure storage sdk'''\n",
    "def downloadBlob(blobclient):\n",
    "    with open(\"/tmp/\"+blobclient.blob_name, \"wb\") as my_blob_dl:\n",
    "        blob_data = blobclient.download_blob()\n",
    "        blob_data.readinto(my_blob_dl)\n",
    "    print(\"Blob %s downloaded\" %blobclient.blob_name)\n",
    "    print(\"Blob path: /tmp/%s\" %blobclient.blob_name)\n",
    "\n",
    "\n",
    "''' getPrediction function sends curl request to Surfrider AI'''\n",
    "''' video name is the name of a locally downloaded video from Azure'''\n",
    "''' video name is passed as an argument to curl_request script '''\n",
    "''' curl_request script sends actual POST request to Surfrider AI'''\n",
    "def getPrediction(video_name):\n",
    "    curl_request_script = ['./curl_request_param.sh',video_name]\n",
    "    output = []\n",
    "    request_answer = subprocess.Popen(curl_request_script, stdout=subprocess.PIPE)\n",
    "    i = 0\n",
    "    for line in request_answer.stdout:\n",
    "        print(line)\n",
    "        output.append(line)\n",
    "    return output\n",
    "\n",
    "\n",
    "''' jsonPrediction cast a prediction from getPrediction function '''\n",
    "''' from a list prediction to a string then dictionnary with json_loads '''\n",
    "def jsonPrediction(pred):\n",
    "    string_prediction = str(pred[0])[2:-3] #removing 2 x first and 3 last characters of pred\n",
    "    json_prediction = json.loads(string_prediction)\n",
    "    return json_prediction\n",
    "\n",
    "\n",
    "''' getTrashLabel return label from a frame_to_box'''\n",
    "def getTrashLabel(frame_2_box):\n",
    "    return frame_2_box['label']\n",
    "\n",
    "''' mapLabelTrashId is a switch that converts label to TrashId'''\n",
    "''' param is label that comes from AI predictions dictionnary jsonPrediction'''\n",
    "def mapLabel2TrashId(label):\n",
    "    switcher = { \n",
    "    \"Fishing or Hunting\":\"89B44BAA-69AA-4109-891A-128E012E7E07\",\n",
    "    \"Food Packaging\":\"185FEFA2-EEF2-47A8-873E-26032A4BB3C3\",\n",
    "    \"Unknown\":\"BB4DEA69-218A-40CC-A000-2AE17C37152C\",\n",
    "    \"Industrial or Construction Debris\":\"2A863E38-E5D0-455F-87CE-2B75DA29F59A\",\n",
    "    \"fragments\":\"ED401B92-DC24-44C0-A52A-34CE831092BF\",\n",
    "    \"Agricultural Waste\":\"36B2AFEB-7A7C-44B5-A790-5E5C73BA144D\",\n",
    "    \"others\":\"4BEC18FC-BC48-45B7-AFDA-6BA96BD80921\",\n",
    "    \"Common Household Items\":\"C68E90CF-6E65-4474-BC60-72E1C8513F55\",\n",
    "    \"plastic\":\"6961D0DB-928C-419E-9985-98EEEAF552C7\",\n",
    "    \"bottles\":\"9780940B-D06C-4AAB-8003-AB914981E87A\",\n",
    "    \"Drinking Bottles\":\"BCF549A8-AECD-4BC9-B9B8-B94A8F3758D5\",\n",
    "    \"Unknown10\":\"BC7BB564-BE04-4B4B-9913-FF69780B93A6\"\n",
    "    } \n",
    "    return switcher.get(label, \"nothing\")\n",
    "\n",
    "\n",
    "''' trashInsert execute INSERT request to dbo.Trash table'''\n",
    "''' parameter to indsert is a trashTypeId defined in Trash_Type table'''\n",
    "def trashInsert(cursor,cnxn,trashTypeId):\n",
    "    cursor.execute(\"INSERT dbo.Trash (Id,CampaignId,Latitude,Longitude,TrashTypeId,Precision,AI_Version) VALUES (NEWID(),'8D21A132-CF4B-404E-B287-C40A2F12D305','50.797731', '2.179029', ? ,'0.95','0')\",trashTypeId)\n",
    "    cnxn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # blob storage connection string\n",
    "    connection_string = os.getenv(\"CONN_STRING\")\n",
    " \n",
    "    # get list of blobs in container campaign0\n",
    "    campaign_container_name = 'campaign0'\n",
    "    #campaign_container_name = 'campaign1'\n",
    "    blobs_campaign0 = blobInContainer(connection_string,campaign_container_name)\n",
    "    print(blobs_campaign0)\n",
    "\n",
    "    # get infos of blob video vid1-4K.MP4,vid1-4K2.MP4,vid1-4K3.mp4,vid1-4K4.mp4,19022020_Adour_6.mp4\n",
    "#    blob_video_name = '19022020_Adour_6.mp4'\n",
    "    blob_video_name = 'vid1-4K4.mp4'   \n",
    "    blobInfos(connection_string,campaign_container_name,blob_video_name)\n",
    "\n",
    "    # download blob video\n",
    "    blob_video0 = BlobClient.from_connection_string(conn_str=connection_string,container_name=campaign_container_name, blob_name=blob_video_name)\n",
    "    downloadBlob(blob_video0)\n",
    "\n",
    "    # get predictions from AI on vid1-4K4.MP4\n",
    "    prediction = getPrediction(blob_video_name)\n",
    "\n",
    "    # cast prediction to JSON/Dictionnary format\n",
    "    json_prediction = jsonPrediction(prediction)\n",
    "    json_prediction\n",
    "\n",
    "    # SQL connection\n",
    "    server = os.getenv(\"SERVER\")\n",
    "    database = os.getenv(\"DATABASE\")\n",
    "    username = os.getenv(\"USERNAME\")\n",
    "    password = os.getenv(\"PWD\")\n",
    "    driver= '{ODBC Driver 17 for SQL Server}'\n",
    "    cnxn = pyodbc.connect('DRIVER='+driver+';SERVER='+server+';PORT=1433;DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "    cursor = cnxn.cursor()\n",
    "\n",
    "    # Executing INSERT for all trash detected in json_prediction from vid1-4K4.MP4\n",
    "    for frame_to_box in json_prediction['detected_trash']:\n",
    "        print(frame_to_box)\n",
    "        trashLabel = getTrashLabel(frame_to_box)\n",
    "        print(trashLabel)\n",
    "        mapLabel = mapLabel2TrashId(trashLabel)\n",
    "        print(mapLabel)\n",
    "        trashInsert(cursor,cnxn,mapLabel)\n",
    "    \n",
    "    # Visualize main result within dbo.Trash Table\n",
    "    cursor.execute(\"SELECT * FROM dbo.Trash\")\n",
    "    row = cursor.fetchone()\n",
    "    while row:\n",
    "        print (str(row[0]))\n",
    "        row = cursor.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute main function\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SQL Ops - Optional check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL Prequesite\n",
    "server = os.getenv(\"SERVER\")\n",
    "database = os.getenv(\"DATABASE\")\n",
    "username = os.getenv(\"USERNAME\")\n",
    "password = os.getenv(\"PWD\")\n",
    "driver= '{ODBC Driver 17 for SQL Server}'\n",
    "cnxn = pyodbc.connect('DRIVER='+driver+';SERVER='+server+';PORT=1433;DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "cursor = cnxn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT all record from dbo.Trash\n",
    "cursor.execute(\"SELECT * FROM dbo.Trash\")\n",
    "row = cursor.fetchone()\n",
    "while row:\n",
    "    for i in range(0,5):\n",
    "        print (str(row[i]))\n",
    "    row = cursor.fetchone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE ALL RECORD from Trash table\n",
    "cursor.execute(\"DELETE FROM dbo.Trash\")\n",
    "cnxn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}